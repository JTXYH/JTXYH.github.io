(window.webpackJsonp=window.webpackJsonp||[]).push([[70],{568:function(s,t,a){"use strict";a.r(t);var e=a(6),n=Object(e.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",[s._v("爬虫框架")])]),s._v(" "),a("h2",{attrs:{id:"scrapy简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scrapy简介"}},[s._v("#")]),s._v(" Scrapy简介")]),s._v(" "),a("p",[a("strong",[s._v("Scrapy是一个Python编写的开源网络爬虫框架。它是一个被设计用于爬取网络数据、提取结构性数据的框架")])]),s._v(" "),a("p",[s._v("官网："),a("a",{attrs:{href:"https://scrapy.org",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://scrapy.org/"),a("OutboundLink")],1)]),s._v(" "),a("h3",{attrs:{id:"工作流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#工作流程"}},[s._v("#")]),s._v(" 工作流程")]),s._v(" "),a("p",[a("a",{attrs:{"data-fancybox":"",title:"scrapy工作流程",href:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy工作流程.png"}},[a("img",{attrs:{src:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png",alt:"scrapy工作流程"}})])]),s._v(" "),a("ol",[a("li",[s._v("爬虫中起始的url构造成request对象--\x3e爬虫中间件--\x3e引擎--\x3e调度器")]),s._v(" "),a("li",[s._v("调度器把request--\x3e引擎--\x3e下载中间件---\x3e下载器")]),s._v(" "),a("li",[s._v("下载器发送请求，获取response响应----\x3e下载中间件----\x3e引擎---\x3e爬虫中间件---\x3e爬虫")]),s._v(" "),a("li",[s._v("爬虫提取url地址，组装成request对象----\x3e爬虫中间件---\x3e引擎---\x3e调度器，重复步骤2")]),s._v(" "),a("li",[s._v("爬虫提取数据---\x3e引擎---\x3e管道处理和保存数据")])]),s._v(" "),a("h3",{attrs:{id:"内置对象模块"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#内置对象模块"}},[s._v("#")]),s._v(" 内置对象模块")]),s._v(" "),a("ul",[a("li",[s._v("request请求对象：由"),a("code",[s._v("url method post_data headers")]),s._v("等构成")]),s._v(" "),a("li",[s._v("response响应对象：由"),a("code",[s._v("url body status headers")]),s._v("等构成")]),s._v(" "),a("li",[s._v("item数据对象：本质是个字")])]),s._v(" "),a("p",[a("a",{attrs:{"data-fancybox":"",title:"scrapy组件",href:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy组件.png"}},[a("img",{attrs:{src:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy%E7%BB%84%E4%BB%B6.png",alt:"scrapy组件"}})])]),s._v(" "),a("h2",{attrs:{id:"简单使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简单使用"}},[s._v("#")]),s._v(" 简单使用")]),s._v(" "),a("p",[s._v("安装："),a("code",[s._v("pip install scrapy")])]),s._v(" "),a("p",[s._v("创建项目："),a("code",[s._v("scrapy startproject 项目名称")])]),s._v(" "),a("p",[a("a",{attrs:{"data-fancybox":"",title:"scrapy入门使用-1",href:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy入门使用-1.png"}},[a("img",{attrs:{src:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8-1.png",alt:"scrapy入门使用-1"}})])]),s._v(" "),a("p",[s._v("生成爬虫：进入项目目录执行"),a("code",[s._v("scrapy genspider 爬虫名称 允许爬取的域名")])]),s._v(" "),a("p",[a("a",{attrs:{"data-fancybox":"",title:"scrapy入门使用-2",href:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy入门使用-2.png"}},[a("img",{attrs:{src:"https://gitee.com/jtxyh/blogImg/raw/master/scrapy%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8-2.png",alt:"scrapy入门使用-2"}})])]),s._v(" "),a("p",[s._v("启用管道，修改"),a("strong",[s._v("settings.py")])]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("ITEM_PIPELINES "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'myspider.pipelines.xxxSpider'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("400")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])])]),a("p",[s._v("运行爬虫：进入项目目录执行 "),a("code",[s._v("scrapy crawl itcast")])]),s._v(" "),a("h3",{attrs:{id:"小结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),a("ul",[a("li",[s._v("scrapy的安装："),a("code",[s._v("pip install scrapy")])]),s._v(" "),a("li",[s._v("创建scrapy的项目: "),a("code",[s._v("scrapy startproject myspider")])]),s._v(" "),a("li",[s._v("创建scrapy爬虫：在项目目录下执行 "),a("code",[s._v("scrapy genspider xx xx.cn")])]),s._v(" "),a("li",[s._v("运行scrapy爬虫：在项目目录下执行 "),a("code",[s._v("scrapy crawl xx")])]),s._v(" "),a("li",[s._v("解析并获取scrapy爬虫中的数据：\n"),a("ol",[a("li",[s._v("response.xpath方法的返回结果是一个类似list的类型，其中包含的是selector对象，操作和列表一样，但是有一些额外的方法")]),s._v(" "),a("li",[a("strong",[s._v("extract() 返回一个包含有字符串的列表")])]),s._v(" "),a("li",[a("strong",[s._v("extract_first() 返回列表中的第一个字符串，列表为空没有返回None")])])])]),s._v(" "),a("li",[s._v("scrapy管道的"),a("strong",[s._v("基本使用")]),s._v(":\n"),a("ol",[a("li",[s._v("完善pipelines.py中的process_item函数")]),s._v(" "),a("li",[s._v("在settings.py中设置开启pipeline")])])]),s._v(" "),a("li",[s._v("response响应对象的"),a("strong",[s._v("常用属性")]),s._v(" "),a("ol",[a("li",[a("code",[s._v("response.url")]),s._v("：当前响应的url地址")]),s._v(" "),a("li",[a("code",[s._v("response.request.url")]),s._v("：当前响应对应的请求的url地址")]),s._v(" "),a("li",[a("code",[s._v("response.headers")]),s._v("：响应头")]),s._v(" "),a("li",[a("code",[s._v("response.requests.headers")]),s._v("：当前响应的请求头")]),s._v(" "),a("li",[a("code",[s._v("response.body")]),s._v("：响应体，也就是html代码，byte类型")]),s._v(" "),a("li",[a("code",[s._v("response.status")]),s._v("：响应状态码")])])])]),s._v(" "),a("h2",{attrs:{id:"管道"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#管道"}},[s._v("#")]),s._v(" 管道")]),s._v(" "),a("p",[s._v("管道配置文件是"),a("code",[s._v("pipelines.py")])]),s._v(" "),a("ol",[a("li",[a("code",[s._v("process_item(self,item,spider)")]),s._v(":\n"),a("ul",[a("li",[s._v("管道类中必须有的函数")]),s._v(" "),a("li",[s._v("实现对item数据的处理")]),s._v(" "),a("li",[s._v("必须return item")])])]),s._v(" "),a("li",[a("code",[s._v("open_spider(self, spider)")]),s._v(": 在爬虫开启的时候仅执行一次")]),s._v(" "),a("li",[a("code",[s._v("close_spider(self, spider)")]),s._v(": 在爬虫关闭的时候仅执行一")])]),s._v(" "),a("h3",{attrs:{id:"例子"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#例子"}},[s._v("#")]),s._v(" 例子")]),s._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" json\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" pymongo "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" MongoClient\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyFilePipeline")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("open_spider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在爬虫开启的时候仅执行一次")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 代码逻辑")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("close_spider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在爬虫关闭的时候仅执行一次")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 代码逻辑")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("process_item")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 代码逻辑")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 不return的情况下，另一个权重较低的pipeline将不会获得item")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" item\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyMongoPipeline")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("open_spider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在爬虫开启的时候仅执行一次")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 代码逻辑")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("process_item")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 代码逻辑")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 不return的情况下，另一个权重较低的pipeline将不会获得item")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" item\n")])])]),a("h3",{attrs:{id:"开启管道"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#开启管道"}},[s._v("#")]),s._v(" 开启管道")]),s._v(" "),a("p",[s._v("在"),a("code",[s._v("settings.py")]),s._v("设置开启pipeline")]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("ITEM_PIPELINES "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'myspider.pipelines.MyFilePipeline'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("400")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 400表示权重")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'myspider.pipelines.MyMongoPipeline'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 权重值越小，越优先执行！")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])])]),a("h3",{attrs:{id:"注意"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#注意"}},[s._v("#")]),s._v(" 注意")]),s._v(" "),a("ol",[a("li",[s._v("使用之前需要在settings中开启")]),s._v(" "),a("li",[s._v("pipeline在setting中键表示位置(即pipeline在项目中的位置可以自定义)，值表示距离引擎的远近，越近数据会越先经过："),a("strong",[s._v("权重值小的优先执行")])]),s._v(" "),a("li",[s._v("有多个pipeline的时候，process_item的方法必须return item,否则后一个pipeline取到的数据为None值")]),s._v(" "),a("li",[s._v("pipeline中process_item的方法必须有，否则item没有办法接受和处理")]),s._v(" "),a("li",[s._v("process_item方法接受item和spider，其中spider表示当前传递item过来的spider")]),s._v(" "),a("li",[s._v("open_spider(spider) :能够在爬虫开启的时候执行一次")]),s._v(" "),a("li",[s._v("close_spider(spider) :能够在爬虫关闭的时候执行一次")]),s._v(" "),a("li",[s._v("上述俩个方法经常用于爬虫和数据库的交互，在爬虫开启的时候建立和数据库的连接，在爬虫关闭的时候断开和数据库的连接")])]),s._v(" "),a("h2",{attrs:{id:"中间件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#中间件"}},[s._v("#")]),s._v(" 中间件")]),s._v(" "),a("p",[s._v("根据scrapy运行流程中所在位置不同分为："),a("code",[s._v("下载中间件和爬虫中间件")]),s._v("，两种中间件都在"),a("code",[s._v("middlewares.py一个文件中")])]),s._v(" "),a("h3",{attrs:{id:"方法介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方法介绍"}},[s._v("#")]),s._v(" 方法介绍")]),s._v(" "),a("ul",[a("li",[a("p",[a("code",[s._v("process_request(self, request, spider)")]),s._v("：")]),s._v(" "),a("ol",[a("li",[s._v("当每个request通过下载中间件时，该方法被调用。")]),s._v(" "),a("li",[s._v("返回None值：没有return也是返回None，该request对象传递给下载器，或通过引擎传递给其他权重低的process_request方法")]),s._v(" "),a("li",[s._v("返回Response对象：不再请求，把response返回给引擎")]),s._v(" "),a("li",[s._v("返回Request对象：把request对象通过引擎交给调度器，此时将不通过其他权重低的process_request方法")])])]),s._v(" "),a("li",[a("p",[a("code",[s._v("process_response(self, request, response, spider)")]),s._v("：")]),s._v(" "),a("ol",[a("li",[s._v("当下载器完成http请求，传递响应给引擎的时候调用")]),s._v(" "),a("li",[s._v("返回Resposne：通过引擎交给爬虫处理或交给权重更低的其他下载中间件的process_response方法")]),s._v(" "),a("li",[s._v("返回Request对象：通过引擎交给调取器继续请求，此时将不通过其他权重低的process_request方法")])])])]),s._v(" "),a("h3",{attrs:{id:"自定义中间件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#自定义中间件"}},[s._v("#")]),s._v(" 自定义中间件")]),s._v(" "),a("p",[s._v("在"),a("code",[s._v("settings.py")]),s._v("中添加")]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("USER_AGENTS_LIST "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5"')]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])])]),a("p",[s._v("在"),a("code",[s._v("middlewares.py")]),s._v("中添加代码")]),s._v(" "),a("div",{staticClass:"language-py extra-class"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" random\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" Tencent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("settings "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" USER_AGENTS_LIST "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 注意导入路径,请忽视pycharm的错误提示")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("UserAgentMiddleware")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("process_request")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        user_agent "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("USER_AGENTS_LIST"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" user_agent\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 不写return")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CheckUA")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("process_response")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" response "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 不能少！")]),s._v("\n")])])]),a("p",[s._v("在"),a("code",[s._v("settings.py中开启")])]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("DOWNLOADER_MIDDLEWARES "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Test.middlewares.UserAgentMiddleware'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("543")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 543是权重值")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Test.middlewares.CheckUA'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("600")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 先执行543权重的中间件，再执行600的中间件")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])])]),a("h2",{attrs:{id:"scrapy-splash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scrapy-splash"}},[s._v("#")]),s._v(" scrapy_splash")]),s._v(" "),a("p",[a("strong",[s._v("scrapy_splash是scrapy的一个组件")])]),s._v(" "),a("ul",[a("li",[s._v("scrapy-splash加载js数据是基于Splash来实现的。")]),s._v(" "),a("li",[s._v("Splash是一个Javascript渲染服务。它是一个实现了HTTP API的轻量级浏览器，Splash是用Python和Lua语言实现的，基于Twisted和QT等模块构建。")]),s._v(" "),a("li",[s._v("使用"),a("strong",[s._v("scrapy-splash最终拿到的response相当于是在浏览器全部渲染完成以后的网页源代码")])])]),s._v(" "),a("h3",{attrs:{id:"docker安装"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#docker安装"}},[s._v("#")]),s._v(" docker安装")]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("docker run -d -p "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8050")]),s._v(":8050 scrapinghub/splash\n")])])]),a("p",[s._v("访问 "),a("code",[s._v("127.0.0.1:8050")]),s._v(" 查看")]),s._v(" "),a("h3",{attrs:{id:"python使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python使用"}},[s._v("#")]),s._v(" python使用")]),s._v(" "),a("p",[s._v("安装："),a("code",[s._v("pip install scrapy-splash")])]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("scrapy startproject test_splash\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" test_splash\nscrapy genspider no_splash baidu.com\nscrapy genspider with_splash baidu.com\n")])])]),a("p",[s._v("修改"),a("code",[s._v("settings.py")])]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 渲染服务的url")]),s._v("\nSPLASH_URL "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'http://127.0.0.1:8050'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 下载器中间件")]),s._v("\nDOWNLOADER_MIDDLEWARES "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scrapy_splash.SplashCookiesMiddleware'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("723")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scrapy_splash.SplashMiddleware'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("725")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("810")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 去重过滤器")]),s._v("\nDUPEFILTER_CLASS "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scrapy_splash.SplashAwareDupeFilter'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用Splash的Http缓存")]),s._v("\nHTTPCACHE_STORAGE "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scrapy_splash.SplashAwareFSCacheStorage'")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Obey robots.txt rules")]),s._v("\nROBOTSTXT_OBEY "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("\n")])])]),a("p",[s._v("使用")]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" scrapy_splash "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" SplashRequest "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用scrapy_splash包提供的request对象")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("WithSplashSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'with_splash'")]),s._v("\n    allowed_domains "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'baidu.com'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://www.baidu.com/s?wd=13161933309'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("start_requests")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" SplashRequest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("start_urls"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                            callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse_splash"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                            args"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'wait'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 最大超时时间，单位：秒")]),s._v("\n                            endpoint"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'render.html'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用splash服务的固定参数")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse_splash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'with_splash.html'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'w'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("body"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])])]),a("h3",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[s._v("#")]),s._v(" 总结")]),s._v(" "),a("p",[a("strong",[s._v("scrapy_splash组件的作用")])]),s._v(" "),a("ol",[a("li",[s._v("splash类似selenium，能够像浏览器一样访问请求对象中的url地址")]),s._v(" "),a("li",[s._v("能够按照该url对应的响应内容依次发送请求")]),s._v(" "),a("li",[s._v("并将多次请求对应的多次响应内容进行渲染")]),s._v(" "),a("li",[s._v("最终返回渲染后的response响应对象")])]),s._v(" "),a("p",[a("strong",[s._v("scrapy_splash组件的使用")])]),s._v(" "),a("ol",[a("li",[s._v("需要splash服务作为支撑")]),s._v(" "),a("li",[s._v("构造的request对象变为splash.SplashRequest")]),s._v(" "),a("li",[s._v("以下载中间件的形式使用")]),s._v(" "),a("li",[s._v("需要scrapy_splash特定配置")])])])}),[],!1,null,null,null);t.default=n.exports}}]);